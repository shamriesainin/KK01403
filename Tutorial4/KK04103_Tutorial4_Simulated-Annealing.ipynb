{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 4 - Simulated Annealing\n",
    "Simulated annealing is a stochastic global search optimization algorithm.\n",
    "\n",
    "# Example 1\n",
    "Convex unimodal optimization function 1 dimensional objective function, x^2 with bounds [-5,5] and its plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import arange\n",
    "from numpy import asarray\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# objective function\n",
    "def objective(x):\n",
    "    return x[0]**2.0\n",
    " \n",
    "# define range for input to the objective function\n",
    "bounds = asarray([[-5.0, 5.0]])\n",
    "\n",
    "# define range for input\n",
    "r_min, r_max = -5.0, 5.0\n",
    "# sample input range uniformly at 0.1 increments\n",
    "inputs = arange(r_min, r_max, 0.1)\n",
    "# compute targets\n",
    "results = [objective([x]) for x in inputs]\n",
    "# create a line plot of input vs result\n",
    "pyplot.plot(inputs, results)\n",
    "# define optimal input value\n",
    "x_optima = 0.0\n",
    "# draw a vertical line at the optimal input\n",
    "pyplot.axvline(x=x_optima, ls='--', color='red')\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulated annealing algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulated_annealing(objective, bounds, n_iterations, step_size, temp):\n",
    "    # generate an initial point\n",
    "    best = bounds[:, 0] + rand(len(bounds)) * (bounds[:, 1] - bounds[:, 0])\n",
    "    \n",
    "    # evaluate the initial point\n",
    "    best_eval = objective(best)\n",
    "    \n",
    "    # current working solution\n",
    "    curr, curr_eval = best, best_eval\n",
    "\n",
    "    # run the algorithm\n",
    "    for i in range(n_iterations):\n",
    "        # take a step\n",
    "        candidate = curr + randn(len(bounds)) * step_size\n",
    "\n",
    "        # CALL the OBJECTIVE FUNCTION & evaluate candidate point\n",
    "        candidate_eval = objective(candidate)\n",
    "\n",
    "        # check for new best solution\n",
    "        if candidate_eval < best_eval:\n",
    "            # store new best point\n",
    "            best, best_eval = candidate, candidate_eval\n",
    "            \n",
    "            # report progress\n",
    "            print('>%d f(%s) = %.5f' % (i, best, best_eval))\n",
    "            \n",
    "        # difference between candidate and current point evaluation\n",
    "        diff = candidate_eval - curr_eval\n",
    "        \n",
    "        # calculate temperature for current epoch\n",
    "        t = temp / float(i + 1)\n",
    "        \n",
    "        # calculate metropolis acceptance criterion\n",
    "        metropolis = exp(-diff / t)\n",
    "        \n",
    "        # check if we should keep the new point\n",
    "        if diff < 0 or rand() < metropolis:\n",
    "            # store the new current point\n",
    "            curr, curr_eval = candidate, candidate_eval\n",
    "\n",
    "        return [best, best_eval]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we apply the optimization algorithm to the problem, letâ€™s take a moment to understand the acceptance criterion. \n",
    "\n",
    "1. First, the fast annealing schedule is an exponential function of the number of iterations. \n",
    "2. Creating a plot of the temperature for each algorithm iteration will show this.\n",
    "3. The initial temperature of 10 and 100 algorithm iterations, both arbitrarily chosen.\n",
    "4. It can be seen that temperature drops rapidly, exponentially, not linearly, such that after 20 iterations it is below 1 and stays low for the remainder of the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore temperature vs algorithm iteration for simulated annealing\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# total iterations of algorithm\n",
    "iterations = 100\n",
    "\n",
    "# initial temperature\n",
    "initial_temp = 10\n",
    "# array of iterations from 0 to iterations - 1\n",
    "iterations = [i for i in range(iterations)]\n",
    "# temperatures for each iterations\n",
    "temperatures = [initial_temp/float(i + 1) for i in iterations]\n",
    "# plot iterations vs temperatures\n",
    "pyplot.plot(iterations, temperatures)\n",
    "pyplot.xlabel('Iteration')\n",
    "pyplot.ylabel('Temperature')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The metropolis acceptance criterion\n",
    "where, differences = [0.01, 0.1, 1.0]\n",
    "and metropolis = exp(-diff / t)\n",
    "1. Experiment on how the metropolis acceptance criterion changes over time with the temperature.\n",
    "2. The plot has three lines for three differences between the new worse solution and the current working solution, according to \n",
    "3. The worse the solution is (the larger the difference), the less likely the model is to accept the worse solution regardless of the algorithm iteration, as we might expect. \n",
    "4. In all cases, the likelihood of accepting worse solutions decreases with algorithm iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore metropolis acceptance criterion for simulated annealing\n",
    "from math import exp\n",
    "from matplotlib import pyplot\n",
    "# total iterations of algorithm\n",
    "iterations = 100\n",
    "# initial temperature\n",
    "initial_temp = 10\n",
    "# array of iterations from 0 to iterations - 1\n",
    "iterations = [i for i in range(iterations)]\n",
    "# temperatures for each iterations\n",
    "temperatures = [initial_temp/float(i + 1) for i in iterations]\n",
    "# metropolis acceptance criterion\n",
    "differences = [0.01, 0.1, 1.0]\n",
    "for d in differences:\n",
    "    metropolis = [exp(-d/t) for t in temperatures]\n",
    "    # plot iterations vs metropolis\n",
    "    label = 'diff=%.2f' % d\n",
    "    pyplot.plot(iterations, metropolis, label=label)\n",
    "# inalize plot\n",
    "pyplot.xlabel('Iteration')\n",
    "pyplot.ylabel('Metropolis Criterion')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to solve the objective function x^2, let's use the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulated annealing search of a one-dimensional objective function\n",
    "from numpy import asarray\n",
    "from numpy import exp\n",
    "from numpy.random import randn\n",
    "from numpy.random import rand\n",
    "from numpy.random import seed\n",
    "\n",
    "# objective function\n",
    "def objective(x):\n",
    "\treturn x[0]**2.0\n",
    "\n",
    "# simulated annealing algorithm\n",
    "def simulated_annealing(objective, bounds, n_iterations, step_size, temp):\n",
    "\t# generate an initial point\n",
    "\tbest = bounds[:, 0] + rand(len(bounds)) * (bounds[:, 1] - bounds[:, 0])\n",
    "\t# evaluate the initial point\n",
    "\tbest_eval = objective(best)\n",
    "\t# current working solution\n",
    "\tcurr, curr_eval = best, best_eval\n",
    "\t# run the algorithm\n",
    "\tfor i in range(n_iterations):\n",
    "\t\t# take a step\n",
    "\t\tcandidate = curr + randn(len(bounds)) * step_size\n",
    "\t\t# evaluate candidate point\n",
    "\t\tcandidate_eval = objective(candidate)\n",
    "\t\t# check for new best solution\n",
    "\t\tif candidate_eval < best_eval:\n",
    "\t\t\t# store new best point\n",
    "\t\t\tbest, best_eval = candidate, candidate_eval\n",
    "\t\t\t# report progress\n",
    "\t\t\tprint('>%d f(%s) = %.5f' % (i, best, best_eval))\n",
    "\t\t# difference between candidate and current point evaluation\n",
    "\t\tdiff = candidate_eval - curr_eval\n",
    "\t\t# calculate temperature for current epoch\n",
    "\t\tt = temp / float(i + 1)\n",
    "\t\t# calculate metropolis acceptance criterion\n",
    "\t\tmetropolis = exp(-diff / t)\n",
    "\t\t# check if we should keep the new point\n",
    "\t\tif diff < 0 or rand() < metropolis:\n",
    "\t\t\t# store the new current point\n",
    "\t\t\tcurr, curr_eval = candidate, candidate_eval\n",
    "\treturn [best, best_eval]\n",
    "\n",
    "# seed the pseudorandom number generator\n",
    "seed(1)\n",
    "# define range for input\n",
    "bounds = asarray([[-5.0, 5.0]])\n",
    "# define the total iterations\n",
    "n_iterations = 1000\n",
    "# define the maximum step size\n",
    "step_size = 0.1\n",
    "# initial temperature\n",
    "temp = 10\n",
    "# perform the simulated annealing search\n",
    "best, score = simulated_annealing(objective, bounds, n_iterations, step_size, temp)\n",
    "print('Done!')\n",
    "print('f(%s) = %f' % (best, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2\n",
    "Let us use the Simulated Annealing algorithm using a bit longer objective function: -2*(x+6)*(x+2)*(x-3)*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# objective function\n",
    "def objective(x):\n",
    "    return -2*(x[0]+6)*(x[0]+2)*(x[0]-3)*x[0]\n",
    " \n",
    "x = np.linspace(-6,3,40)\n",
    "#y = np.linspace(-10,10,40)\n",
    "plt.plot(x,-2*(x+6)*(x+2)*(x-3)*x) #objective function\n",
    "# define optimal input value\n",
    "x_optima = -1.02\n",
    "# draw a vertical line at the optimal input\n",
    "plt.axvline(x=x_optima, ls='--', color='red')\n",
    "\n",
    "#plt.plot(x, x**2.0 + y**2.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulated annealing search of a one-dimensional objective function\n",
    "from numpy import asarray\n",
    "from numpy import exp\n",
    "from numpy.random import randn\n",
    "from numpy.random import rand\n",
    "from numpy.random import seed\n",
    "\n",
    "# objective function\n",
    "def objective(x):\n",
    "\treturn -2*(x+6)*(x+2)*(x-3)*x\n",
    "\n",
    "# simulated annealing algorithm\n",
    "def simulated_annealing(objective, bounds, n_iterations, step_size, temp):\n",
    "\t# generate an initial point\n",
    "\tbest = bounds[:, 0] + rand(len(bounds)) * (bounds[:, 1] - bounds[:, 0])\n",
    "\t# evaluate the initial point\n",
    "\tbest_eval = objective(best)\n",
    "\t# current working solution\n",
    "\tcurr, curr_eval = best, best_eval\n",
    "\t# run the algorithm\n",
    "\tfor i in range(n_iterations):\n",
    "\t\t# take a step\n",
    "\t\tcandidate = curr + randn(len(bounds)) * step_size\n",
    "\t\t# evaluate candidate point\n",
    "\t\tcandidate_eval = objective(candidate)\n",
    "\t\t# check for new best solution\n",
    "\t\tif candidate_eval < best_eval:\n",
    "\t\t\t# store new best point\n",
    "\t\t\tbest, best_eval = candidate, candidate_eval\n",
    "\t\t\t# report progress\n",
    "\t\t\tprint('>%d f(%s) = %.5f' % (i, best, best_eval))\n",
    "\t\t# difference between candidate and current point evaluation\n",
    "\t\tdiff = candidate_eval - curr_eval\n",
    "\t\t# calculate temperature for current epoch\n",
    "\t\tt = temp / float(i + 1)\n",
    "\t\t# calculate metropolis acceptance criterion\n",
    "\t\tmetropolis = exp(-diff / t)\n",
    "\t\t# check if we should keep the new point\n",
    "\t\tif diff < 0 or rand() < metropolis:\n",
    "\t\t\t# store the new current point\n",
    "\t\t\tcurr, curr_eval = candidate, candidate_eval\n",
    "\treturn [best, best_eval]\n",
    "\n",
    "# seed the pseudorandom number generator\n",
    "seed(1)\n",
    "# define range for input\n",
    "bounds = asarray([[-6.0, 3.0]])\n",
    "# define the total iterations\n",
    "n_iterations = 1000\n",
    "# define the maximum step size\n",
    "step_size = 0.1\n",
    "# initial temperature\n",
    "temp = 10\n",
    "# perform the simulated annealing search\n",
    "best, score = simulated_annealing(objective, bounds, n_iterations, step_size, temp)\n",
    "print('Done!')\n",
    "print('f(%s) = %f' % (best, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "Based on the above implementation, instead of finding the global minimum, use the simulated aneealing algorithm to find the global maximum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3 - Dual Annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulated annealing global optimization for a multimodal objective function\n",
    "from scipy.optimize import dual_annealing\n",
    " \n",
    "# objective function\n",
    "def objective(v):\n",
    "    x, y = v\n",
    "    #return (x**2 + y - 11)**2 + (x + y**2 -7)**2\n",
    "    return x**2.0 + y**2.0\n",
    " \n",
    "# define range for input\n",
    "r_min, r_max = -5.0, 5.0\n",
    "\n",
    "# define the bounds on the search\n",
    "bounds = [[r_min, r_max], [r_min, r_max]]\n",
    "\n",
    "# perform the simulated annealing search\n",
    "result = dual_annealing(objective, bounds)\n",
    "\n",
    "# summarize the result\n",
    "print('Status : %s' % result['message'])\n",
    "print('Total Evaluations: %d' % result['nfev'])\n",
    "\n",
    "# evaluate solution\n",
    "solution = result['x']\n",
    "evaluation = objective(solution)\n",
    "print('Solution: f(%s) = %.5f' % (solution, evaluation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 4 - Non-convex function\n",
    "obj = 0.2 + x1^2 + x2^2 - 0.1(math.cos(6.0 x 3.1415 x x1) - 0.1x math.cos(6.0 x 3.1415x x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate a contour plot\n",
    "# Import some other libraries that we'll need\n",
    "# matplotlib and numpy packages must also be installed\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "\n",
    "# define objective function\n",
    "def f(x):\n",
    "    x1 = x[0]\n",
    "    x2 = x[1]\n",
    "    obj = 0.2 + x1**2 + x2**2 - 0.1*math.cos(6.0*3.1415*x1) - 0.1*math.cos(6.0*3.1415*x2)\n",
    "    return obj\n",
    "\n",
    "# Start location\n",
    "x_start = [0.8, -0.5]\n",
    "\n",
    "# Design variables at mesh points\n",
    "i1 = np.arange(-1.0, 1.0, 0.01)\n",
    "i2 = np.arange(-1.0, 1.0, 0.01)\n",
    "x1m, x2m = np.meshgrid(i1, i2)\n",
    "fm = np.zeros(x1m.shape)\n",
    "for i in range(x1m.shape[0]):\n",
    "    for j in range(x1m.shape[1]):\n",
    "        fm[i][j] = 0.2 + x1m[i][j]**2 + x2m[i][j]**2 \\\n",
    "             - 0.1*math.cos(6.0*3.1415*x1m[i][j]) \\\n",
    "             - 0.1*math.cos(6.0*3.1415*x2m[i][j])\n",
    "\n",
    "# Create a contour plot\n",
    "plt.figure()\n",
    "# Specify contour lines\n",
    "#lines = range(2,52,2)\n",
    "# Plot contours\n",
    "CS = plt.contour(x1m, x2m, fm)#,lines)\n",
    "# Label contours\n",
    "plt.clabel(CS, inline=1, fontsize=10)\n",
    "# Add some text to the plot\n",
    "plt.title('Non-Convex Function')\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "\n",
    "##################################################\n",
    "# Simulated Annealing\n",
    "##################################################\n",
    "# Number of cycles\n",
    "n = 50\n",
    "# Number of trials per cycle\n",
    "m = 50\n",
    "# Number of accepted solutions\n",
    "na = 0.0\n",
    "# Probability of accepting worse solution at the start\n",
    "p1 = 0.7\n",
    "# Probability of accepting worse solution at the end\n",
    "p50 = 0.001\n",
    "\n",
    "# Initial temperature\n",
    "t1 = -1.0/math.log(p1)\n",
    "\n",
    "# Final temperature\n",
    "t50 = -1.0/math.log(p50)\n",
    "\n",
    "# Fractional reduction every cycle\n",
    "frac = (t50/t1)**(1.0/(n-1.0))\n",
    "\n",
    "# Initialize x\n",
    "x = np.zeros((n+1,2))\n",
    "x[0] = x_start\n",
    "xi = np.zeros(2)\n",
    "xi = x_start\n",
    "na = na + 1.0\n",
    "\n",
    "# Current best results so far\n",
    "xc = np.zeros(2)\n",
    "xc = x[0]\n",
    "fc = f(xi)\n",
    "fs = np.zeros(n+1)\n",
    "fs[0] = fc\n",
    "\n",
    "# Current temperature\n",
    "t = t1\n",
    "\n",
    "# DeltaE Average\n",
    "DeltaE_avg = 0.0\n",
    "\n",
    "for i in range(n):\n",
    "    print('Cycle: ' + str(i) + ' with Temperature: ' + str(t))\n",
    "    for j in range(m):\n",
    "        # Generate new trial points\n",
    "        xi[0] = xc[0] + random.random() - 0.5\n",
    "        xi[1] = xc[1] + random.random() - 0.5\n",
    "        # Clip to upper and lower bounds\n",
    "        xi[0] = max(min(xi[0],1.0),-1.0)\n",
    "        xi[1] = max(min(xi[1],1.0),-1.0)\n",
    "        DeltaE = abs(f(xi)-fc)\n",
    "        \n",
    "        if (f(xi)>fc):\n",
    "            # Initialize DeltaE_avg if a worse solution was found\n",
    "            #   on the first iteration\n",
    "            if (i==0 and j==0): DeltaE_avg = DeltaE\n",
    "            # objective function is worse\n",
    "            # generate probability of acceptance\n",
    "            p = math.exp(-DeltaE/(DeltaE_avg * t))\n",
    "            # determine whether to accept worse point\n",
    "            if (random.random()<p):\n",
    "                # accept the worse solution\n",
    "                accept = True\n",
    "            else:\n",
    "                # don't accept the worse solution\n",
    "                accept = False\n",
    "        else:\n",
    "            # objective function is lower, automatically accept\n",
    "            accept = True\n",
    "        if (accept==True):\n",
    "            # update currently accepted solution\n",
    "            xc[0] = xi[0]\n",
    "            xc[1] = xi[1]\n",
    "            fc = f(xc)\n",
    "            # increment number of accepted solutions\n",
    "            na = na + 1.0\n",
    "            # update DeltaE_avg\n",
    "            DeltaE_avg = (DeltaE_avg * (na-1.0) +  DeltaE) / na\n",
    "    # Record the best x values at the end of every cycle\n",
    "    x[i+1][0] = xc[0]\n",
    "    x[i+1][1] = xc[1]\n",
    "    fs[i+1] = fc\n",
    "    # Lower the temperature for next cycle\n",
    "    t = frac * t\n",
    "\n",
    "# print solution\n",
    "print('Best solution: ' + str(xc))\n",
    "print('Best objective: ' + str(fc))\n",
    "\n",
    "plt.plot(x[:,0],x[:,1],'y-o')\n",
    "plt.savefig('contour.png')\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.plot(fs,'r.-')\n",
    "ax1.legend(['Objective'])\n",
    "ax2 = fig.add_subplot(212)\n",
    "ax2.plot(x[:,0],'b.-')\n",
    "ax2.plot(x[:,1],'g--')\n",
    "ax2.legend(['x1','x2'])\n",
    "\n",
    "# Save the figure as a PNG\n",
    "#plt.savefig('iterations.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
